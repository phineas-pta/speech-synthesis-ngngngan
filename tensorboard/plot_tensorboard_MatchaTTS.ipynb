{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"4h50min audio at 22.05 kHz = 820 MiB disk space\n",
				"\n",
				"log data point every 50 steps, save ckpt every 20 epoch\n",
				"\n",
				"batch size = 16 ⇒ 1 epoch = 354 steps\n",
				"\n",
				"train locally from scratch, ≈ 3 minute/epoch (without eval valid set) - 5 minute/epoch (with eval valid set)\n",
				"\n",
				"train ?? epochs, select ckpt at last epoch"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import numpy as np\n",
				"import pandas as pd\n",
				"from scipy.signal import lfilter\n",
				"import matplotlib.pyplot as plt\n",
				"from matplotlib.ticker import EngFormatter"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"from the author of Matcha-TTS:\n",
				"- Looking at the mel spectrograms of the referenced audio, the dataset seems quite noisy ⇐ *singing, timestamp mismatch, misspelling, whisper hallucinations*\n",
				"- The loss seems to be behaving fine for the flow matching loss and enc loss.\n",
				"- In terms of duration loss overall for epoch, it is also decreasing but, for step, it is very noisy I suspect some text and audio mismatch in some batches,\n",
				"- keep an eye on that and train the model for a bit more, I think it will improve further :)\n",
				"- One hack that you can do is after some training, train the model further with a batch size 1 for 1 epoch and see which samples are giving absurd loss and investigate the reason behind them."
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
